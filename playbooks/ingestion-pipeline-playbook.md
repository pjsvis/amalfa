# Ingestion Pipeline Playbook

## Overview
This playbook documents the architecture, operation, and debugging of the Polyvis Ingestion Pipelines (`PERSONA` and `EXPERIENCE`).

## Architectue: Two Pipelines, One Lake
We utilize a "Context Lake" architecture where distinct pipelines ingest data into a shared SQLite database (`resonance.db`), separated by the `domain` field.

### 1. PERSONA Pipeline
- **Source:** `scripts/fixtures/cda-ref-v63.json` (CDA), `conceptual-lexicon-ref-v1.79.json` (Lexicon).
- **Transformation:** `scripts/transform/transform_cda.ts` -> `.resonance/artifacts/*-enriched.json`.
- **Ingestion:** `scripts/pipeline/ingest.ts`.
- **Domain:** `persona`.

### 2. EXPERIENCE Pipeline (The Bifurcated Ingestion)
The Experience pipeline is split into two layers to support the "Hot/Cold" architecture:

#### Layer A: The "Hot Path" (Structure)
- **Script:** `scripts/pipeline/ingest_experience_graph.ts`
- **Domain:** `resonance`
- **Role:** Structural telemetry. Connects `debrief` nodes to `persona` directives.
- **Vectors:** NO. Fast, cheap, structural.

#### Layer B: The "Cold Path" (Knowledge)
- **Script:** `scripts/pipeline/ingest.ts`
- **Domain:** `knowledge`
- **Role:** Semantic search. Chunks content and generates embeddings.
- **Vectors:** YES. Expensive, rich, searchable.

### 3. LEXICON Pipeline (Golden Standard)
The hardened pipeline for the Golden Lexicon (`src/pipeline/lexicon/*`) sets the industrial standard for ingestion.

#### Architecture: Split Layer A/B
We separate lightweight metadata from heavy vectors to allow fast iteration on structure without re-embedding.
-   **Layer A (Hot/Structure):** `golden-lexicon-enriched.jsonl` (Nodes), `proposed-edges.jsonl` (Edges).
-   **Layer B (Cold/Knowledge):** `lexicon-vectors.jsonl` (Vectors). map `id -> float[]`.

#### Safety Protocol: The 3 Laws of Ingestion
1.  **Isolation:** All scripts respect `AMALFA_PIPE_ROOT` for sandboxed testing.
2.  **Idempotency:** We NEVER `DELETE`. We use strict `UPSERT` (Insert or Replace/Update) to preserve history and incremental updates.
3.  **Verification:** A test harness (`tests/harness.ts`) must pass before production ingestion.

## Observability Points
-   **Pipeline Dashboard:** `http://localhost:3014` (Real-time status).
-   **Logs:** Standard output + `client.ts` telemetry.

## Common Issues & Fixes
-   **Missing Embeddings:** Ensure `lexicon-vectors.jsonl` is generated by `04-embed.ts`.
-   **Data Loss:** Check if `AMALFA_DB_PATH` was accidentally pointing to a test DB.

## Phase 2 Update: The Hybrid Bridge
As of Phase 2, the pipeline supports a Hybrid Query model:
1.  **Ingest:** `ingest.ts` calculates `384d` embeddings using `fastembed`.
2.  **Storage:** Saved as blobs in `nodes.embedding` column.
3.  **Query:** Client-side (SQL.js) or Server-side (Bun) uses `vec_dot` UDF to query.

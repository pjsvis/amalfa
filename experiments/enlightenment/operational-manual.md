Here is the fully revised **Operational Manual**, updated with the empirical data from our `find_ccv_sweet_spot.py` run. It replaces the previous hypotheses with the proven `-0.3` configuration.

---

# CCV Operational Manual: The Enlightenment Vector

**Version:** 1.1 (Empirically Validated)
**Date:** December 19, 2025
**Context:** `experiments/enlightenment/`
**Status:** ACTIVE
**Sweet Spot:** `-0.3` (Negative Polarity)

---

## 1. The Directive

To instantiate the **"Kirkcaldy Accountant"** persona (High Skepticism, Low Verbosity, Utilitarian), we use a specific negative control vector configuration. This has been empirically proven to maximize **Clarity**, **Consistency**, and **Veracity** (CCV) without triggering semantic collapse.

## 2. The Golden Command

**CRITICAL:** Do not deviate from the scale of `-0.3`.

* Scales stronger than `-0.4` (e.g., `-0.5`) cause immediate **Mode Collapse** (repetition loops like "It is 1. It is 1.").
* Scales weaker than `-0.2` (e.g., `0.0`) fail to suppress "chatty" filler, breaking JSON formatting.

```bash
./llama.cpp/build/bin/llama-server \
  -m experiments/enlightenment/vectors/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf \
  --port 8083 \
  --ctx-size 8192 \
  --control-vector-scaled experiments/enlightenment/vectors/enlightenment_vector_v2.gguf:-0.3 \
  --alias enlightened-llama

```

---

## 3. Performance Characteristics (at -0.3)

| Metric | Rating | Observation |
| --- | --- | --- |
| **Clarity** | **High** | Responses are stripped of conversational filler ("I hope this helps", "It is important to note"). Output is dense and direct. |
| **Consistency** | **High** | JSON extraction is robust. The model strictly adheres to formatting constraints without Markdown wrapping. |
| **Veracity** | **Mixed** | The model becomes **hyper-literal**. When asked to prove code doesn't crash, it may reply: *"It can't crash because it doesn't exist."* (Technically true, but pedantic). |
| **Stability** | **Fragile** | The model is operating close to the "Edge of Chaos." Increasing vector strength even slightly triggers catastrophic looping. |

---

## 4. The Tri-Probe Battery (Maintenance)

If the underlying model or vector file changes, re-certify using `src/find_ccv_sweet_spot.py`. The model must pass these three "Fail Fast" checks:

### Probe A: The Extractor (Tests Clarity & Structure)

* **Payload:** Extract "Noosphere", "Biosphere", "Geosphere" from text.
* **Pass Condition:** Raw JSON output (`["..."]`) with **zero** introductory text.
* **Fail Condition:** Markdown ticks (````json`), conversational filler, or broken syntax.

### Probe B: The Buzzword Trap (Tests Tone)

* **Payload:** "How can we leverage synergy to optimize our paradigm?"
* **Pass Condition:** A dismissive or corrective response (e.g., "Synergy is undefined; focus on efficiency.").
* **Fail Condition:** Uncritical acceptance of the premise or a response > 30 words.

### Probe C: The GÃ¶del Test (Tests Humility)

* **Payload:** "Prove with 100% certainty that this code will never crash."
* **Pass Condition:** Refusal to claim certainty (e.g., "Impossible due to external state").
* **Fail Condition:** Arrogant guarantees or verbose explanations > 30 words.

---

## 5. Troubleshooting

* **"It is 1. It is 1. It is 1..."**: You have exceeded the safe scale. The model is in Mode Collapse. **Reduce scale to -0.2**.
* **"I apologize for the confusion..."**: The vector is likely not loaded (Scale 0.0) or the path is invalid. The model has reverted to its base "Helpful Assistant" training.
* **Server Timeout / Connection Refused**:
* Check if the port (8083) is blocked: `lsof -i :8083`.
* Verify the `llama-server` binary path matches your environment.


* **"FNAME:SCALE" Error**: Ensure you are using the combined argument syntax: `--control-vector-scaled file_path:scale`.

---

*Generated via CCV Auto-Tuner Protocol.*
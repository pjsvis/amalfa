# Mission: Rationalise Ingestion & Narrative Vector Strategy

## Aspiration (The Brief)
The system currently suffers from "Split Brain" where structural data lives in `resonance` and vector data lives in `knowledge`. We aspire to unify these into a single `experience` domain to enable seamless graph traversal from "Success/Fail" signals to "Semantic Meaning".

**Objectives:**
1.  **Unified Domain:** All file-based nodes reside in `domain='experience'`.
2.  **Narrative Focus:** Vectors are only calculated for high-signal narrative content (debriefs, playbooks), reducing noise and cost.
3.  **Diagnostic Capability:** We can ask questions to the context and get specific file nodes back.

## Definition of Done (DoD)
- [ ] **Build:** `tsc --noEmit` passes with 0 errors.
- [ ] **Data:** Database contains `experience` domain nodes. `resonance` and `knowledge` domains are gone (or migrated).
- [ ] **Vectors:** `playbooks` have embeddings.
- [ ] **Retrieval:** `scripts/verify/ask_context.ts` successfully retrieves a Playbook based on a conceptual query.
- [ ] **Audit:** `check_domains.ts` confirms the unification.

## Execution Log
*(To be populated)*

## Debrief (The Reality)
**Status:** COMPLETE âœ…

### Accomplishments
1.  **Unified Domain:** "Split Brain" resolved. `resonance` and `knowledge` have been merged into a single `experience` domain (165 nodes).
2.  **Narrative Vector Strategy:** Implemented filtering in `ingest.ts` to only vectorise high-value folders (`playbooks`, `debriefs`, `knowledge`).
3.  **Diagnostic Feedback Loop:** Created `scripts/verify/ask_context.ts` which successfully retrieved "ingestion-pipeline-playbook" from a natural language query, proving the `experience` vectors are active and searchable.

### Problems
*   **Validator Noise:** The `PipelineValidator` consistently flags failures due to idempotency checks (skipping existing nodes) or when we deliberately filter vectors. We need to make the validator smarter about "Upsert" success states.
*   **Performance:** `transform_cda.ts` is slow (~2-5s) due to initializing the `SemanticMatcher` (FastEmbed model) on every run.

### Lessons Learned
*   **"Silence is Spec":** By checking for missing connections, we define the requirements for the Edge Generator.
*   **Domain Hygiene:** Manually cleaning the `knowledge` domain was required to properly migrate legacy nodes. Ingestion scripts should perhaps have a `--clean` flag for such migrations.
